{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe9b1d4",
   "metadata": {},
   "source": [
    "######  CÓDIGO BASE PARA DETECCIÓN DE CORROSIÓN  #####\n",
    "------------------------------------------------------\n",
    "||  Código por: Rafael Rolando Calvo Román           ||\n",
    "||  Fecha: 28/09/20250                               ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d9e47a",
   "metadata": {},
   "source": [
    "// Línea de código para instalar las librerías necesarias para la comunicación con Gemini //\n",
    "--------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ad1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: pillow in c:\\users\\asus\\anaconda3\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-generativeai) (2.183.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.8)\n",
      "Requirement already satisfied: pydantic in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-generativeai) (2.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->google-generativeai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-generativeai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9d3a8",
   "metadata": {},
   "source": [
    "// Utilizar el API key para la conexión con Gemini //\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Reemplaza con tu API Key de Gemini\n",
    "genai.configure(api_key=\"API_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927beb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Verificación de modelos de Gemini habilitados //\n",
    "--------------------------------------------------\n",
    "No es necesario compilarlo de nuevo, solo fue para el desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfcea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 -> ['embedText', 'countTextTokens']\n",
      "models/gemini-2.5-pro-preview-03-25 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-05-20 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-06-17 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-05-06 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro-preview-06-05 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp -> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation -> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-preview-image-generation -> ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-pro-exp-02-05 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-thinking-exp-1219 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts -> ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts -> ['countTokens', 'generateContent']\n",
      "models/learnlm-2.0-flash-experimental -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-1b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it -> ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it -> ['generateContent', 'countTokens']\n",
      "models/gemini-flash-latest -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-flash-lite-latest -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-pro-latest -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-image-preview -> ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-preview-09-2025 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-09-2025 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-robotics-er-1.5-preview -> ['generateContent', 'countTokens']\n",
      "models/embedding-001 -> ['embedContent']\n",
      "models/text-embedding-004 -> ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 -> ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-exp -> ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-001 -> ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "models/aqa -> ['generateAnswer']\n",
      "models/imagen-3.0-generate-002 -> ['predict']\n",
      "models/imagen-4.0-generate-preview-06-06 -> ['predict']\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 -> ['predict']\n",
      "models/imagen-4.0-generate-001 -> ['predict']\n",
      "models/imagen-4.0-ultra-generate-001 -> ['predict']\n",
      "models/imagen-4.0-fast-generate-001 -> ['predict']\n",
      "models/veo-2.0-generate-001 -> ['predictLongRunning']\n",
      "models/veo-3.0-generate-preview -> ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-preview -> ['predictLongRunning']\n",
      "models/veo-3.0-generate-001 -> ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-001 -> ['predictLongRunning']\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog -> ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog -> ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-live-001 -> ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-live-2.5-flash-preview -> ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-live-preview -> ['bidiGenerateContent', 'countTokens']\n",
      "models/gemini-2.5-flash-native-audio-latest -> ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025 -> ['countTokens', 'bidiGenerateContent']\n"
     ]
    }
   ],
   "source": [
    "# Revisar los modelos habilitados en tu cuenta\n",
    "for m in genai.list_models():\n",
    "    print(m.name, \"->\", m.supported_generation_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6146ee",
   "metadata": {},
   "source": [
    "// Envío y recepción del prompt //\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7563bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: No\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAyzWT0qZlkCpnhjcjEzw5ZfYGzSllKhGE\")\n",
    "\n",
    "img = Image.open(r\"C:\\Users\\Asus\\Downloads\\fluttershy.jpg\")\n",
    "\n",
    "# Usa el modelo confirmado de tu lista\n",
    "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
    "\n",
    "response = model.generate_content(\n",
    "    [\"¿La superficie del metal muestra corrosión? Respóndeme sí o no.\", img]\n",
    ")\n",
    "\n",
    "print(\"Respuesta:\", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1980ff1",
   "metadata": {},
   "source": [
    "// Mostrar la respuesta obtenida //\n",
    "----------------------------------\n",
    "\n",
    "Muestra toda la respuesta, no solo lo solicitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5c0e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"S\\u00ed\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 276,\n",
      "        \"candidates_token_count\": 1,\n",
      "        \"total_token_count\": 392\n",
      "      },\n",
      "      \"model_version\": \"gemini-2.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Esto muestra todo lo que devuelve Gemini (útil para debug)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
